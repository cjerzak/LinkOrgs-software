#GOAL 1. To illustrate the inverse propensity weighting method
#       by using Q6 in the homework.
#GOAL 2. Clarify the G_i, P_t, D_i notation using inverse propensity weighting
#In this study, we're going to study the setup in Q6 in the homework.
#In particular, we're going to check out how the bias + variance of the inverse-propensity weighting (IPW) estimator
#behaves under varying degrees of model misspecification!
#clear workspace
rm(list=ls())
library(glmnet) #load in glmnet package for lasso-penalized multinomial logistic reg.
set.seed(2)
T0 <- 1#1 pre-intervention period
T1 <- 1#1 post-intervention period
N = 1000 #total number of units in study
k = 20#how many covariates?
FracEverTreat = 0.5#fraction of units treated
tau = 0.25
seq_CovariateIncorrectlySpecified = round(c(0,k*0.25,k*0.5,k*0.75,k))
biasVec = rep(NA, times = length( seq_CovariateIncorrectlySpecified ))
varVec = rep(NA, times = length( seq_CovariateIncorrectlySpecified ))
counter_i <- 0
for(NumbCovarNonlinear in seq_CovariateIncorrectlySpecified){
print(sprintf("Getting results when %s of %s covariates incorrectly modeled",
NumbCovarNonlinear, k))
counter_i = counter_i + 1
#setup placeholder for inner results
#we need to average over many draws of the model
#with a fixed number of non-linear covariate relations
tauhat_vec = rep(NA,times=100)
for(i in 1:100){
#generate background covariates
X = mvtnorm::rmvnorm(n = N,
mean = rep(0,k),
sigma = diag(k)) #sample covariates -- what do you NOT notice here?
#these are the linear coefficients in the propensity model for G_i.
#we are going to manipulate the degree of non-linearity in X_i
#and see how our linear propensity score model (estimated via logistic regression)
#does at estimating the ATE.
propensity_coefs = rnorm(k)
if(NumbCovarNonlinear == 0){ logitTrue = scale(X %*% propensity_coefs + rnorm(N, sd = 0.25))}
if(NumbCovarNonlinear > 0){
X_transform = sapply(1:NumbCovarNonlinear,
function(i){
x = X[,i]
nonlinear_numb = sample(1:5,1)
if(nonlinear_numb == 1){x = sin(x)}
if(nonlinear_numb == 2){x = (x)^2}
if(nonlinear_numb == 3){x = log(abs(x))}
if(nonlinear_numb == 4){x = 1/(1+exp(-x))}
if(nonlinear_numb == 5){x = abs(x)}
return( x )
} )
X_tilde = cbind(X_transform,X[,-c(1:NumbCovarNonlinear)])
logitTrue = scale( X_tilde %*% propensity_coefs + rnorm(N, sd = 0.25) )
}
propensityTrue = 1 / (1 + exp(- logitTrue ))
#Remember, G_i denotes the ever-treated status of i, NOT its treatment status
G_obs = rbinom(N, size = 1, prob = propensityTrue)
#We could use G_i to construct D_{it}.
#Notice how G_i is indexed only by i. D_{it} is indexed by both i and t
PreIndicator = c(rep(0,times = T0),
rep(1,times = T1))
DMat = matrix(0,nrow = N,ncol=T0+T1)
DMat[G_obs==1,] <-t(replicate(c(PreIndicator), n = sum(G_obs==1)))
head(G_obs)
head(DMat)
#Notice the difference!
#Now, we can generate the observed outcomes.
outcome_coefs <- rnorm(k)
YPeriod0 <- X %*% outcome_coefs + rnorm(N, sd = 0.20)
YPeriod1 <- YPeriod0 + tau * G_obs + rnorm(N, sd = 0.50 * abs(YPeriod0)) #what is this scaling in the sd doing?
#Let's move on to the estimation!
#First, we need to estimate the propensity scores
#We  do so using lasso-regularized multionomial regression model
#regularization penalty chosen via 10-fold cross-validation
library(glmnet)
my_lasso = cv.glmnet(x = X,
y = as.matrix(G_obs),
family = "binomial",
type.measure = "class",
nfolds = 10,
alpha = 1)
#plot( my_lasso )
#Grab predicted probabilities
#s = lambda.min means that we want the predicted probabilities
#when the regularization penalty minimizes the mis-classification error
propensityEst = c( predict(my_lasso, s = "lambda.min", newx = X))
tauhat_vec[i] = mean( c(YPeriod1 - YPeriod0) * (G_obs - propensityEst) /
(propensityEst * (1-propensityEst)) )
}
#store bias and variance given DGP
biasVec[counter_i] <- mean(tauhat_vec - tau)
varVec[counter_i] <- var(tauhat_vec)
}
#Great! We're ready to plot our results
#Would you expect things to behave in a linear way or
#non-linear way with respect to the fraction of
#covariates incorrectly specified?
plot(seq_CovariateIncorrectlySpecified/k, abs(biasVec),
xlab = "fraction of covariates incorrectly specified",
ylab = "Absolute Bias")
plot(seq_CovariateIncorrectlySpecified/k, varVec,
xlab = "fraction of covariates incorrectly specified",
ylab = "Variance")
plot(seq_CovariateIncorrectlySpecified/k, varVec+biasVec^2,
xlab = "fraction of covariates incorrectly specified",
ylab = "Mean-squared Error (MSE)")
#!! Answer: Non-linear relationships due to fact that tau-hat is not
#a linear function of the estimated propensities.
#We're using the wrong model and the way in which errors in
#model specification propogate is non-linear (rather hard to capture analytically).
#Notice that the problem isn't only due to propensities going near to 0 or near to 1
#To see this, just check this out (the estimated propensities from the last iteration)
hist( propensityEst )
#The estimated propensities are actually centered around 0.5 here.
#The true propensities are closer to 0 and 1 (but even this is not a severe problem here)
hist( propensityTrue )
rm(list=ls())
library(glmnet) #load in glmnet package for lasso-penalized multinomial logistic reg.
set.seed(2)
T0 <- 1#1 pre-intervention period
T1 <- 1#1 post-intervention period
N = 1000 #total number of units in study
k = 20#how many covariates?
FracEverTreat = 0.5#fraction of units treated
tau = 0.25
N = 1000 #total number of units in study
seq_CovariateIncorrectlySpecified = round(c(0,k*0.25,k*0.5,k*0.75,k))
seq_CovariateIncorrectlySpecified
biasVec = rep(NA, times = length( seq_CovariateIncorrectlySpecified ))
varVec = rep(NA, times = length( seq_CovariateIncorrectlySpecified ))
counter_i <- 0
seq_CovariateIncorrectlySpecified
print(sprintf("Getting results when %s of %s covariates incorrectly modeled",
NumbCovarNonlinear, k))
counter_i = counter_i + 1
#setup placeholder for inner results
#we need to average over many draws of the model
#with a fixed number of non-linear covariate relations
tauhat_vec = rep(NA,times=100)
#generate background covariates
X = mvtnorm::rmvnorm(n = N,
mean = rep(0,k),
sigma = diag(k)) #sample covariates -- what do you NOT notice here?
dim(seq_CovariateIncorrectlySpecified)
#generate background covariates
X = mvtnorm::rmvnorm(n = N,
mean = rep(0,k),
sigma = diag(k)) #sample covariates -- what do you NOT notice here?
X
dim(X )
#Remember, G_i denotes the ever-treated status of i, NOT its treatment status
G_obs = rbinom(N, size = 1, prob = propensityTrue)
G_obs
propensityTrue = 1 / (1 + exp(- logitTrue ))
#GOAL 1. To illustrate the inverse propensity weighting method
#       by using Q6 in the homework.
#GOAL 2. Clarify the G_i, P_t, D_i notation using inverse propensity weighting
#In this study, we're going to study the setup in Q6 in the homework.
#In particular, we're going to check out how the bias + variance of the inverse-propensity weighting (IPW) estimator
#behaves under varying degrees of model misspecification!
#clear workspace
rm(list=ls())
library(glmnet) #load in glmnet package for lasso-penalized multinomial logistic reg.
set.seed(2)
T0 <- 1#1 pre-intervention period
T1 <- 1#1 post-intervention period
N = 1000 #total number of units in study
k = 20#how many covariates?
FracEverTreat = 0.5#fraction of units treated
tau = 0.25
seq_CovariateIncorrectlySpecified = round(c(0,k*0.25,k*0.5,k*0.75,k))
biasVec = rep(NA, times = length( seq_CovariateIncorrectlySpecified ))
varVec = rep(NA, times = length( seq_CovariateIncorrectlySpecified ))
counter_i <- 0
for(NumbCovarNonlinear in seq_CovariateIncorrectlySpecified){
print(sprintf("Getting results when %s of %s covariates incorrectly modeled",
NumbCovarNonlinear, k))
counter_i = counter_i + 1
#setup placeholder for inner results
#we need to average over many draws of the model
#with a fixed number of non-linear covariate relations
tauhat_vec = rep(NA,times=100)
for(i in 1:100){
#generate background covariates
X = mvtnorm::rmvnorm(n = N,
mean = rep(0,k),
sigma = diag(k)) #sample covariates -- what do you NOT notice here?
#these are the linear coefficients in the propensity model for G_i.
#we are going to manipulate the degree of non-linearity in X_i
#and see how our linear propensity score model (estimated via logistic regression)
#does at estimating the ATE.
propensity_coefs = rnorm(k)
if(NumbCovarNonlinear == 0){ logitTrue = scale(X %*% propensity_coefs + rnorm(N, sd = 0.25))}
if(NumbCovarNonlinear > 0){
X_transform = sapply(1:NumbCovarNonlinear,
function(i){
x = X[,i]
nonlinear_numb = sample(1:5,1)
if(nonlinear_numb == 1){x = sin(x)}
if(nonlinear_numb == 2){x = (x)^2}
if(nonlinear_numb == 3){x = log(abs(x))}
if(nonlinear_numb == 4){x = 1/(1+exp(-x))}
if(nonlinear_numb == 5){x = abs(x)}
return( x )
} )
X_tilde = cbind(X_transform,X[,-c(1:NumbCovarNonlinear)])
logitTrue = scale( X_tilde %*% propensity_coefs + rnorm(N, sd = 0.25) )
}
propensityTrue = 1 / (1 + exp(- logitTrue ))
#Remember, G_i denotes the ever-treated status of i, NOT its treatment status
G_obs = rbinom(N, size = 1, prob = propensityTrue)
#We could use G_i to construct D_{it}.
#Notice how G_i is indexed only by i. D_{it} is indexed by both i and t
PreIndicator = c(rep(0,times = T0),
rep(1,times = T1))
DMat = matrix(0,nrow = N,ncol=T0+T1)
DMat[G_obs==1,] <-t(replicate(c(PreIndicator), n = sum(G_obs==1)))
head(G_obs)
head(DMat)
#Notice the difference!
#Now, we can generate the observed outcomes.
outcome_coefs <- rnorm(k)
YPeriod0 <- X %*% outcome_coefs + rnorm(N, sd = 0.20)
YPeriod1 <- YPeriod0 + tau * G_obs + rnorm(N, sd = 0.50 * abs(YPeriod0)) #what is this scaling in the sd doing?
#Let's move on to the estimation!
#First, we need to estimate the propensity scores
#We  do so using lasso-regularized multionomial regression model
#regularization penalty chosen via 10-fold cross-validation
library(glmnet)
my_lasso = cv.glmnet(x = X,
y = as.matrix(G_obs),
family = "binomial",
type.measure = "class",
nfolds = 10,
alpha = 1)
#plot( my_lasso )
#Grab predicted probabilities
#s = lambda.min means that we want the predicted probabilities
#when the regularization penalty minimizes the mis-classification error
propensityEst = c( predict(my_lasso, s = "lambda.min", newx = X))
tauhat_vec[i] = mean( c(YPeriod1 - YPeriod0) * (G_obs - propensityEst) /
(propensityEst * (1-propensityEst)) )
}
#store bias and variance given DGP
biasVec[counter_i] <- mean(tauhat_vec - tau)
varVec[counter_i] <- var(tauhat_vec)
}
#Great! We're ready to plot our results
#Would you expect things to behave in a linear way or
#non-linear way with respect to the fraction of
#covariates incorrectly specified?
plot(seq_CovariateIncorrectlySpecified/k, abs(biasVec),
xlab = "fraction of covariates incorrectly specified",
ylab = "Absolute Bias")
#Great! We're ready to plot our results
#Would you expect things to behave in a linear way or
#non-linear way with respect to the fraction of
#covariates incorrectly specified?
plot(seq_CovariateIncorrectlySpecified/k, abs(biasVec),
xlab = "fraction of covariates incorrectly specified",
ylab = "Absolute Bias")
plot(seq_CovariateIncorrectlySpecified/k, varVec,
xlab = "fraction of covariates incorrectly specified",
ylab = "Variance")
foreign::read.dta
foreign::read.dta("./Downloads/Vietnam-2015-full data.dta")
my_dta = foreign::read.dta("./Downloads/Vietnam-2015-full data.dta")
my_dta = foreign::read.dta("./Downloads/Vietnam-2015-full data.dta")
head(my_dta[,1:5])
my_dta[1,]
mean(rewards_allP0_vec,na.rm=T)
mean(rewards_allP1_vec,na.rm=T)
mean(rewards_naive,na.rm=T)
rm(list=ls())
library(fuzzyjoin);library(tidyverse)
factor2numeric <- function(x){as.numeric(as.character(x))}
#setwd("~/Dropbox/Directory")
library(data.table)
devtools::install_github("cjerzak/LinkIt-software/LinkIt");
library(LinkIt)
LinkIt(x=c(), y=c(),by.x = "NM_LGL",by.y="comnam",parallelize = T)
load("./LinkIt_directory.Rdata")
directory
data("LinkIt_directory_trigrams.Rdata", "LinkIt_directory_trigrams.Rdata", package="LinkIt", envir=parent.env(environment()))
Linkit::
LinkIt::directory
LinkIt:::directory
LinkIt::LinkIt
data("LinkIt_directory_trigrams", "LinkIt_directory_trigrams", package="LinkIt", envir=parent.env(environment()))
devtools::install_github("cjerzak/LinkIt-software/LinkIt");
q()
q()
rm(list=ls())
library(fuzzyjoin);library(tidyverse)
factor2numeric <- function(x){as.numeric(as.character(x))}
#setwd("~/Dropbox/Directory")
library(data.table)
library(LinkIt)
LinkIt(x=c(), y=c(),by.x = "NM_LGL",by.y="comnam",parallelize = T)
directory
LinkIt:::directory
data("LinkIt_directory.Rdata", envir=environment())
data("LinkIt_directory_trigrams.Rdata", envir=environment())
ls()
list.files()
data
?data
data(LinkIt_directory_trigrams.Rdata,package="LinkIt")
data("LinkIt_directory_trigrams.Rdata",package="LinkIt")
data(file="LinkIt_directory_trigrams.Rdata",package="LinkIt")
save(1, file = "TEMP.Rdata")
save(x, file = "TEMP.Rdata")
load("TEMP.Rdata")
load("TEMP")
data("TEMP")
data("TEMP.Rdata")
x
devtools::install_github("cjerzak/LinkIt-software/LinkIt");
q()
rm(list=ls())
library(fuzzyjoin);library(tidyverse)
factor2numeric <- function(x){as.numeric(as.character(x))}
#setwd("~/Dropbox/Directory")
library(data.table)
devtools::install_github("cjerzak/LinkIt-software/LinkIt");
library(LinkIt)
#LinkIt(x=c(), y=c(),by.x = "NM_LGL",by.y="comnam",parallelize = T)
options(stringsAsFactors = F)
LinkIt(x=c(), y=c(),by.x = "NM_LGL",by.y="comnam",parallelize = T)
data("LinkIt_directory.Rdata", package="LinkIt",envir=environment())
data(LinkIt_directory_trigrams, package="LinkIt", envir=environment())
data
data
data
directory
directory
data("LinkIt_directory_trigrams.Rdata", package="LinkIt", envir=environment())
q()
rm(list=ls())
library(fuzzyjoin);library(tidyverse)
factor2numeric <- function(x){as.numeric(as.character(x))}
library(data.table); library(sqldf);library(stringdist)
#setwd("~/Dropbox/Directory")
devtools::install_github("cjerzak/LinkIt-software/LinkIt");
library(LinkIt)
LinkIt(x=c(), y=c(),by.x = "NM_LGL",by.y="comnam",parallelize = T)
LinkedThem_directory
load("/Users/cjerzak/Dropbox/Directory/LinkIt-software/LinkIt/R/sysdata.Rda")
devtools::use_data(LinkedThem_directory,internal=T)
?devtools::use_data
LinkIt::LinkedThem_directory
data(LinkedThem_directory,package="LinkIt")
data(,package="LinkIt")
list.data
list.dirs(,package="LinkIt")
q(0)
q()
rm(list=ls())
library(fuzzyjoin);library(tidyverse)
factor2numeric <- function(x){as.numeric(as.character(x))}
library(data.table); library(sqldf);library(stringdist)
#setwd("~/Dropbox/Directory")
devtools::install_github("cjerzak/LinkIt-software/LinkIt");
library(LinkIt)
#load in data
load("./STARTUP_POINT.Rdata")
#let's sample the ones which definitely have matches
sample_ = sample(1:nrow(z_human),nrow(z_human))
sampled_rssd = z_human$rssd[sample_]
sampled_permco = z_human$permco[sample_]
x_red = x[sample(1:nrow(x),1000),]#[x$rssd %in% sampled_rssd,]
y_red = y[sample(1:nrow(y),1000),]#[y$permco %in% sampled_permco,]
#x_red = x; y_red = y
#why?
f2n(z_human$rssd)[f2n(z_human$rssd) %in% f2n(x$rssd)]
f2n(z_human$rssd)[!f2n(z_human$rssd) %in% f2n(x$rssd)]
system.time( z_red_exact <- merge(x=x_red, y=y_red,
by.x = "NM_LGL",by.y="comnam") )
x_red1  = x_red; y_red1  = y_red;
x_red1$alias_name = x_red1$NM_LGL
y_red1$alias_name = y_red1$comnam
system.time(z_red_fuzzy <- FastFuzzyMatch_public(x=x_red1, y=y_red1, by.x = "alias_name", by.y = "alias_name",
method = "jw", max_dist = 0.20) )
system.time(z_red_fuzzy_alt <- as.data.frame( stringdist_join(x = x_red1,y = y_red1, by="alias_name", mode = "inner",
ignore_case = FALSE, method = "jw",
max_dist = 0.20, distance_col = "dist")) )
head(z_red_fuzzy[z_red_fuzzy$alias_name.x==z_red_fuzzy$alias_name.x[2],])
head(z_red_fuzzy_alt[tolower(z_red_fuzzy_alt$alias_name.x)==z_red_fuzzy$alias_name.x[2],])
head(z_red_fuzzy_alt)
dim(z_red_fuzzy_alt)
dim(z_red_fuzzy)
z_red_fuzzy = z_red_fuzzy[,!grepl(colnames(z_red_fuzzy),pattern = "alias_name")]
#LinkIt(x=c(), y=c(),by.x = "NM_LGL",by.y="comnam",parallelize = T)
system.time(z_red_LinkIt <- LinkIt(x=x_red, y=y_red,
by.x = "NM_LGL",by.y="comnam",parallelize = T))
LT_d <- directory[,.(alias_name,alias_id,canonical_id)]
temp1 <- tempfile()
download.file("https://github.com/cjerzak/LinkIt-software/raw/master/directory_data.zip",temp1)
temp = unzip(temp1)
load(temp[1])
load(temp[3])
try(file.remove(temp),T)
directory = as.data.table(directory)
directory_trigrams = as.data.table(directory_trigrams)
LT_d <- directory[,.(alias_name,alias_id,canonical_id)]
#LinkIt(x=c(), y=c(),by.x = "NM_LGL",by.y="comnam",parallelize = T)
system.time(z_red_LinkIt <- LinkIt(x=x_red, y=y_red,
by.x = "NM_LGL",by.y="comnam",parallelize = T))
temp1 <- tempfile()
download.file("https://github.com/cjerzak/LinkIt-software/raw/master/directory_data.zip",temp1)
temp = unzip(temp1)
load(temp[1]);load(temp[3])
try(file.remove(temp),T)
directory = as.data.table(directory)
directory_trigrams = as.data.table(directory_trigrams)
LT_d <- directory[,.(alias_name,alias_id,canonical_id)]
LT_d <- directory[,.(alias_name,alias_id,canonical_id)]
q()
rm(list=ls())
library(fuzzyjoin);library(tidyverse)
factor2numeric <- function(x){as.numeric(as.character(x))}
library(data.table); library(sqldf);library(stringdist)
#setwd("~/Dropbox/Directory")
devtools::install_github("cjerzak/LinkIt-software/LinkIt");
library(LinkIt)
#load in data
load("./STARTUP_POINT.Rdata")
#let's sample the ones which definitely have matches
sample_ = sample(1:nrow(z_human),nrow(z_human))
sampled_rssd = z_human$rssd[sample_]
sampled_permco = z_human$permco[sample_]
x_red = x[sample(1:nrow(x),1000),]#[x$rssd %in% sampled_rssd,]
y_red = y[sample(1:nrow(y),1000),]#[y$permco %in% sampled_permco,]
#LinkIt(x=c(), y=c(),by.x = "NM_LGL",by.y="comnam",parallelize = T)
system.time(z_red_LinkIt <- LinkIt(x=x_red, y=y_red,
by.x = "NM_LGL",by.y="comnam",parallelize = T))
directory = as.data.table(directory)
directory_trigrams = as.data.table(directory_trigrams)
LT_d <- directory[,.(alias_name,alias_id,canonical_id)]
directory
temp1 <- tempfile()
download.file("https://github.com/cjerzak/LinkIt-software/raw/master/directory_data.zip",temp1)
temp = unzip(temp1)
load(temp[1]);load(temp[3])
try(file.remove(temp),T)
directory = as.data.table(directory)
directory_trigrams = as.data.table(directory_trigrams)
LT_d <- directory[,.(alias_name,alias_id,canonical_id)]
directory
temp1 <- tempfile()
download.file("https://github.com/cjerzak/LinkIt-software/raw/master/directory_data.zip",temp1)
temp = unzip(temp1)
load(temp[1]);load(temp[3])
try(file.remove(temp),T)
LT_d <- directory[,.(alias_name,alias_id,canonical_id)]
directory = as.data.table(directory)
directory_trigrams = as.data.table(directory_trigrams)
LT_d <- directory[,.(alias_name,alias_id,canonical_id)]
directory
head(directory)
.(alias_name,alias_id,canonical_id)
directory = as.data.table(directory)
directory_trigrams = as.data.table(directory_trigrams)
LT_d <- directory[,.(alias_name,alias_id,canonical_id)]
directory
class(directory)
LT_d <- directory[,.(alias_name,alias_id,canonical_id)]
library(data.table)
LT_d <- directory[,.(alias_name,alias_id,canonical_id)]
LT_d <- directory[,c("alias_name","alias_id","canonical_id")]
x.stop.words = x.words[,.(word.freq=.N/nrow(x)),word][
word.freq > control$x.stopwordcutoff,word
]
LT_d
q()
rm(list=ls())
#library(fuzzyjoin);
library(data.table);
setwd("~/Dropbox/Directory")
#load in data
devtools::install_github("cjerzak/LinkIt-software/LinkIt");
library(LinkIt)
load("./STARTUP_POINT.Rdata")
f2n<-function(x){ as.numeric(as.character(x))}
#let's sample the ones which definitely have matches
sample_ = sample(1:nrow(z_human),nrow(z_human))
sampled_rssd = z_human$rssd[sample_]
sampled_permco = z_human$permco[sample_]
x_red = x[sample(1:nrow(x),1000),]#[x$rssd %in% sampled_rssd,]
y_red = y[sample(1:nrow(y),1000),]#[y$permco %in% sampled_permco,]
#x_red = x; y_red = y
#why?
f2n(z_human$rssd)[f2n(z_human$rssd) %in% f2n(x$rssd)]
f2n(z_human$rssd)[!f2n(z_human$rssd) %in% f2n(x$rssd)]
system.time( z_red_exact <- merge(x=x_red, y=y_red,
by.x = "NM_LGL",by.y="comnam") )
x_red1  = x_red; y_red1  = y_red;
x_red1$alias_name = x_red1$NM_LGL
y_red1$alias_name = y_red1$comnam
system.time(z_red_fuzzy <- FastFuzzyMatch_public(x=x_red1, y=y_red1, by.x = "alias_name", by.y = "alias_name",
method = "jw", max_dist = 0.20,browser=F) )
##################################################
##INSTRUCTIONS FOR PACKAGE DOWNLOAD############
##################################################
package_name <- "LinkIt"
#Generate documentation
{
setwd(sprintf("~/Dropbox/Directory/%s-software",package_name))
devtools::document(sprintf("./%s",package_name))
try(file.remove(sprintf("./%s.pdf",package_name)),T); system(sprintf("R CMD Rd2pdf %s",package_name))
}
q()
